{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KkCanD7nuGY5",
    "outputId": "6290a1f8-4dca-468f-c7b6-c32b4149dfa8"
   },
   "outputs": [],
   "source": [
    "#AUTHORID = 'YA8f5tQAAAAJ'\n",
    "AUTHORID = 'aegDFT4AAAAJ'\n",
    "\n",
    "DATA_PATH = ''\n",
    "# from google.colab import drive\n",
    "# #drive.mount('/content/drive')\n",
    "# drive.mount('/content/drive')\n",
    "# #DATA_PATH = '/content/drive/MyDrive/RPL'\n",
    "# DATA_PATH = '/content/drive'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NH3Vm_DG9Mh-",
    "outputId": "2488d471-b73b-4865-cb88-459b9f5a1047"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\programdata\\anaconda3\\lib\\site-packages (4.11.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from beautifulsoup4) (2.3.2.post1)\n"
     ]
    }
   ],
   "source": [
    "!pip install beautifulsoup4\n",
    "import json, requests, bs4, re, time, sys\n",
    "import openpyxl\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "G3two36HSHuJ"
   },
   "outputs": [],
   "source": [
    "class Publication(object):\n",
    "  def __init__(self, title, year, cited_by,\n",
    "               link=None,\n",
    "               authors=None,\n",
    "               description=None,\n",
    "               citation_histogram=None,\n",
    "               detail_extracted=False,\n",
    "               url=None,\n",
    "               cookies=None):\n",
    "\n",
    "    self.cookies = cookies\n",
    "    self.headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n",
    "                    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "\n",
    "    self.url = url\n",
    "    self.soup = None\n",
    "\n",
    "    self.title = title\n",
    "    self.year = year\n",
    "    self.cited_by = cited_by\n",
    "    self.link = link\n",
    "    self.authors = authors\n",
    "    self.description = description\n",
    "    self.citation_histogram = citation_histogram\n",
    "    self.detail_extracted = detail_extracted\n",
    "\n",
    "  def set_url(self):\n",
    "    return f'https://scholar.google.com/citations?{self.url}'\n",
    "\n",
    "  def make_detail_request(self):\n",
    "    url = self.set_url()\n",
    "    response = requests.request(\"GET\",url,headers=self.headers,cookies=self.cookies)\n",
    "    if response.status_code == 200:\n",
    "      self.detail_extracted = True\n",
    "    return response\n",
    "\n",
    "  # TODO: For some reason, stopped working.\n",
    "  # The response html is different and does not contain this information)\n",
    "  def get_link_to_publication(self):\n",
    "    title = self.soup.find('div', {'id': 'gsc_oci_title'})\n",
    "    if title:\n",
    "      link = title.find('a', {'class': 'gsc_oci_title_link'})\n",
    "      if link:\n",
    "        self.link = link.get('href')\n",
    "\n",
    "  def get_authors(self):\n",
    "    authors = self.soup.find('div', text = re.compile('Authors'), attrs = {'class' : 'gsc_oci_field'})\n",
    "    if authors:\n",
    "      self.authors = authors.parent.find('div', {'class': 'gsc_oci_value'}).get_text().split(', ')\n",
    "    else:\n",
    "      inventors = self.soup.find('div', text = re.compile('Inventors'), attrs = {'class' : 'gsc_oci_field'})\n",
    "      if inventors:\n",
    "        self.authors = inventors.parent.find('div', {'class': 'gsc_oci_value'}).get_text().split(', ')\n",
    "\n",
    "  # TODO: For some reason, stopped working.\n",
    "  # The response html is different and does not contain this information)\n",
    "  def get_description(self):\n",
    "    description = self.soup.find('div', {'id': 'gsc_oci_descr'})\n",
    "    if description:\n",
    "      self.description = description.get_text()\n",
    "\n",
    "  def get_citation_histogram(self):\n",
    "    citation_hist = self.soup.find('div', {'id': 'gsc_oci_graph_bars'})\n",
    "    if citation_hist:\n",
    "      citation_hist_time = list(map(lambda x: int(x.get_text()),citation_hist.find_all('span', {'class': 'gsc_oci_g_t'})))\n",
    "      citation_hist_cites = list(map(lambda x: int(x.get_text()),citation_hist.find_all('span', {'class': 'gsc_oci_g_al'})))\n",
    "      self.citation_histogram = list(zip(citation_hist_time,citation_hist_cites))\n",
    "\n",
    "  def scrape(self):\n",
    "    self.soup = bs4.BeautifulSoup(self.make_detail_request().content, 'lxml')\n",
    "    if self.detail_extracted:\n",
    "      self.get_link_to_publication()\n",
    "      self.get_authors()\n",
    "      self.get_description()\n",
    "      self.get_citation_histogram()\n",
    "    return self.detail_extracted\n",
    "\n",
    "  def export_json(self):\n",
    "    return {'url': self.url,\n",
    "            'title': self.title,\n",
    "            'link': self.link,\n",
    "            'year': self.year,\n",
    "            'cited_by': self.cited_by,\n",
    "            'authors': self.authors,\n",
    "            'description': self.description,\n",
    "            'citation_histogram': self.citation_histogram,\n",
    "            'detail_extracted': self.detail_extracted}\n",
    "\n",
    "\n",
    "class Author(object):\n",
    "  data_path = DATA_PATH\n",
    "\n",
    "  def __init__(self, authorID,\n",
    "               name=None,\n",
    "               image_link=None,\n",
    "               interests=None,\n",
    "               citations=None,\n",
    "               hindex=None,\n",
    "               i10index=None,\n",
    "               citation_histogram=None,\n",
    "               coauthors=None,\n",
    "               publications=None,\n",
    "               all_publications_retrieved=False,\n",
    "               all_publications_extracted=False,\n",
    "               cstart=0,\n",
    "               pagesize=100, # Max page size in scholar\n",
    "               cookies=None):\n",
    "\n",
    "    self.cstart = cstart\n",
    "    self.pagesize = pagesize\n",
    "    self.cookies = cookies\n",
    "    self.headers = {'User-Agent':'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/105.0.0.0 Safari/537.36',\n",
    "                    'accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.9'}\n",
    "\n",
    "    self.soup = None\n",
    "\n",
    "    self.authorID = authorID\n",
    "    self.name = name\n",
    "    self.image_link = image_link\n",
    "    self.interests = interests\n",
    "    self.citations = citations\n",
    "    self.hindex = hindex\n",
    "    self.i10index = i10index\n",
    "    self.citation_histogram = citation_histogram\n",
    "    self.coauthors = coauthors\n",
    "    self.publications = publications\n",
    "    self.all_publications_retrieved = all_publications_retrieved\n",
    "    self.all_publications_extracted = all_publications_extracted\n",
    "\n",
    "  def set_url(self):\n",
    "    return f\"https://scholar.google.com/citations?hl=en&user={self.authorID}&cstart={self.cstart}&pagesize={self.pagesize}\"\n",
    "\n",
    "  def make_profile_request(self):\n",
    "    url = self.set_url()\n",
    "    response = requests.request(\"GET\",url,headers=self.headers,cookies=self.cookies)\n",
    "    if response.status_code == 429:\n",
    "      raise Exception(\"The server responded with Error 429. We have been detected. Wait before trying again.\")\n",
    "    self.cookies = response.cookies\n",
    "    return response\n",
    "\n",
    "  def get_soup(self):\n",
    "    self.soup = bs4.BeautifulSoup(self.make_profile_request().content, 'html.parser')\n",
    "\n",
    "  def make_coauthor_request(self):\n",
    "    url = self.set_url()+'&view_op=list_colleagues'\n",
    "    response = requests.request(\"GET\",url,headers=self.headers)\n",
    "    if response.status_code == 429:\n",
    "      raise Exception(\"The server responded with Error 429. We have been detected. Wait before trying again.\")\n",
    "    return response\n",
    "\n",
    "  def get_full_name(self):\n",
    "    name = self.soup.find('div', {'id': 'gsc_prf_in'})\n",
    "    if name:\n",
    "      self.name = name.get_text()\n",
    "\n",
    "  # TODO: For some reason, stopped working.\n",
    "  # The response html is different and does not contain this information)\n",
    "  def get_image_link(self):\n",
    "    image = self.soup.find('div', {'img': 'gsc_prf_pup-img'})\n",
    "    if image:\n",
    "      self.image_link = image.get('src')\n",
    "\n",
    "  def get_interests(self):\n",
    "    self.interests = list(map(lambda x: x.get_text(), self.soup.find_all('a', {'class': 'gsc_prf_inta'})))\n",
    "\n",
    "  def get_citations_count(self, citation_info):\n",
    "    citation = citation_info.find('a', text = re.compile('Citations'), attrs = {'class' : 'gsc_rsb_f'})\n",
    "    if citation:\n",
    "      citation_value = citation.parent.parent.find_all('td', {'class': 'gsc_rsb_std'})\n",
    "      if len(citation_value)>0:\n",
    "        self.citations = int(citation_value[0].get_text())\n",
    "\n",
    "  def get_hindex(self, citation_info):\n",
    "    hindex = citation_info.find('a', text = re.compile('h-index'), attrs = {'class' : 'gsc_rsb_f'})\n",
    "    if hindex:\n",
    "      hindex_value = hindex.parent.parent.find_all('td', {'class': 'gsc_rsb_std'})\n",
    "      if len(hindex_value)>0:\n",
    "        self.hindex = int(hindex_value[0].get_text())\n",
    "\n",
    "  def get_i10index(self, citation_info):\n",
    "    i10index = citation_info.find('a', text = re.compile('i10-index'), attrs = {'class' : 'gsc_rsb_f'})\n",
    "    if i10index:\n",
    "      i10index_value = i10index.parent.parent.find_all('td', {'class': 'gsc_rsb_std'})\n",
    "      if len(i10index_value)>0:\n",
    "        self.i10index = int(i10index_value[0].get_text())\n",
    "\n",
    "  def get_citation_metrics(self):\n",
    "    citation_info = self.soup.find('div', {'id': 'gsc_rsb_cit'})\n",
    "    if citation_info:\n",
    "      self.get_citations_count(citation_info)\n",
    "      self.get_hindex(citation_info)\n",
    "      self.get_i10index(citation_info)\n",
    "\n",
    "  def get_citation_histogram(self):\n",
    "    citation_hist = self.soup.find_all('div', {'class': 'gsc_md_hist_w'})\n",
    "    if citation_hist:\n",
    "      citation_hist = citation_hist[0]\n",
    "      citation_hist_time = list(map(lambda x: x.get_text(),citation_hist.find_all('span', {'class': 'gsc_g_t'})))\n",
    "      citation_hist_cites = list(map(lambda x: x.get_text(),citation_hist.find_all('a', {'class': 'gsc_g_a'})))\n",
    "      self.citation_histogram = list(zip(citation_hist_time,citation_hist_cites))\n",
    "\n",
    "  def get_coauthors(self):\n",
    "    coauthor_list = self.soup.find('div', {'id': 'gsc_rsb_co'})\n",
    "    if coauthor_list:\n",
    "      if coauthor_list.find('button'): # too many coauthors requires a request\n",
    "        coauthor_list = bs4.BeautifulSoup(self.make_coauthor_request().content, 'html.parser').find('div', {'id': 'gsc_codb_content'})\n",
    "        coauthor_list = coauthor_list.find_all('div', {'class': 'gsc_ucoar'})\n",
    "        coauthor_ids = list(map(lambda x: x.get('id').split('-')[-1], coauthor_list))\n",
    "        coauthor_names = list(map(lambda x: x.find('img').get('alt'), coauthor_list))\n",
    "        self.coauthors = list(zip(coauthor_ids,coauthor_names))\n",
    "      else:\n",
    "        coauthor_list = coauthor_list.find_all('img')\n",
    "        coauthor_ids = list(map(lambda x: x.get('id').split('-')[1], coauthor_list))\n",
    "        coauthor_names = list(map(lambda x: x.get('alt'), coauthor_list))\n",
    "        self.coauthors = list(zip(coauthor_ids,coauthor_names))\n",
    "\n",
    "  def extract_compact_publication(self, publication_element):\n",
    "    title = publication_element.find('a',{\"class\": \"gsc_a_at\"}).get_text()\n",
    "    year = publication_element.find('td',{\"class\": \"gsc_a_y\"}).find('span', {\"class\": \"gsc_a_hc\"}).get_text()\n",
    "    if year:\n",
    "      year = int(year)\n",
    "    else:\n",
    "      year = None\n",
    "    url = publication_element.find('a',{\"class\": \"gsc_a_at\"}).get('href').split('?')[-1]\n",
    "    cited_by = publication_element.find('a',{\"class\": \"gsc_a_ac\"}).get_text()\n",
    "    if cited_by:\n",
    "      cited_by = int(cited_by)\n",
    "    else:\n",
    "      cited_by = None\n",
    "    return Publication(title, year, cited_by, url=url, cookies=self.cookies)\n",
    "\n",
    "  def get_publications_list(self):\n",
    "    publication_list = []\n",
    "    while True:\n",
    "      soup = bs4.BeautifulSoup(self.make_profile_request().content, 'html.parser')\n",
    "      items = soup.find_all('tr', {\"class\": \"gsc_a_tr\"})\n",
    "      if len(items)==1:\n",
    "        if items[0].find('td', {\"class\": \"gsc_a_e\"}):\n",
    "          self.all_publications_retrieved = True\n",
    "          break\n",
    "      publication_list += items\n",
    "      self.cstart += self.pagesize\n",
    "    self.publications = list(map(lambda x: self.extract_compact_publication(x), publication_list))\n",
    "\n",
    "  def get_publications_detail(self):\n",
    "    unscraped_publications = filter(lambda x: not x.detail_extracted, self.publications)\n",
    "    for publication in unscraped_publications:\n",
    "      # time.sleep(5)\n",
    "      successful = publication.scrape()\n",
    "      if not successful:\n",
    "        break\n",
    "    self.set_all_publications_extracted()\n",
    "\n",
    "  def set_all_publications_extracted(self):\n",
    "    checker = next(filter(lambda x: not x.detail_extracted, self.publications),None)\n",
    "    if checker is None:\n",
    "      self.all_publications_extracted = True\n",
    "    else:\n",
    "      self.all_publications_extracted = False\n",
    "\n",
    "  def save_data(self):\n",
    "    data = self.export_json()\n",
    "    with open(f'{self.data_path}/{self.authorID}.json', 'w') as f:\n",
    "      json.dump(data, f)\n",
    "    if self.all_publications_extracted:\n",
    "      print('The data extraction was complete.')\n",
    "      print(f'The extracted information is saved into the \"{self.authorID}.json\" file in the selected data path.')\n",
    "    else:\n",
    "      print('The publication detail extraction was incomplete.')\n",
    "      print(f'The extracted information is saved into the \"{self.authorID}.json\" file in the selected data path.')\n",
    "      print('We will continue to extract the detail of the remaining publications next time you try.')\n",
    "\n",
    "  def export_json(self):\n",
    "    data = {'authorID': self.authorID,\n",
    "            'name': self.name,\n",
    "            'image_link': self.image_link,\n",
    "            'interests': self.interests,\n",
    "            'citations': self.citations,\n",
    "            'hindex': self.hindex,\n",
    "            'i10index': self.i10index,\n",
    "            'citation_histogram': self.citation_histogram,\n",
    "            'coauthors': self.coauthors,\n",
    "            'publications': [],\n",
    "            'all_publications_retrieved': self.all_publications_retrieved,\n",
    "            'all_publications_extracted': self.all_publications_extracted,\n",
    "            'cstart': self.cstart,\n",
    "            'pagesize': self.pagesize}\n",
    "    data['publications'] = list(map(lambda x: x.export_json(), self.publications))\n",
    "    return data\n",
    "\n",
    "  def scrape(self):\n",
    "    if not self.all_publications_retrieved:\n",
    "      self.get_soup()\n",
    "      self.get_full_name()\n",
    "      self.get_image_link()\n",
    "      self.get_interests()\n",
    "      self.get_citation_metrics()\n",
    "      self.get_citation_histogram()\n",
    "      self.get_coauthors()\n",
    "      self.get_publications_list()\n",
    "    if not self.all_publications_extracted:\n",
    "      self.get_publications_detail()\n",
    "    self.save_data()\n",
    "\n",
    "def create_author(authorID):\n",
    "  try:\n",
    "    with open(f'{DATA_PATH}/{authorID}.json', 'r') as f:\n",
    "      data = json.load(f)\n",
    "\n",
    "    publications_data = data.pop('publications')\n",
    "    cstart = data.pop('cstart')\n",
    "    pagesize = data.pop('page')\n",
    "\n",
    "    author = Author(**data)\n",
    "    author.get_soup()\n",
    "    author.cstart = cstart\n",
    "    author.pagesize = pagesize\n",
    "\n",
    "    pubulications = list(map(lambda pub: Publication(**pub, cookies=author.cookies),\n",
    "                            publications_data))\n",
    "    author.publications = pubulications\n",
    "\n",
    "    return author\n",
    "  except:\n",
    "    return Author(authorID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 494
    },
    "id": "kN94mbZ497i9",
    "outputId": "094a2a5d-53e6-439c-e163-83e7d2c3b21f",
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "The server responded with Error 429. We have been detected. Wait before trying again.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12656\\2105787602.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mauthor_obj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_author\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAUTHORID\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mauthor_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mauthor_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_publications_extracted\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12656\\4149049858.py\u001b[0m in \u001b[0;36mscrape\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    291\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mscrape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    292\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall_publications_retrieved\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 293\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    294\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_full_name\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_image_link\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12656\\4149049858.py\u001b[0m in \u001b[0;36mget_soup\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    140\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mget_soup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msoup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbs4\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mBeautifulSoup\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_profile_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'html.parser'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mmake_coauthor_request\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_12656\\4149049858.py\u001b[0m in \u001b[0;36mmake_profile_request\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    135\u001b[0m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"GET\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m429\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The server responded with Error 429. We have been detected. Wait before trying again.\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcookies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcookies\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mException\u001b[0m: The server responded with Error 429. We have been detected. Wait before trying again."
     ]
    }
   ],
   "source": [
    "author_obj = create_author(AUTHORID)\n",
    "author_obj.scrape()\n",
    "author_obj.all_publications_extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_q9-hVeF-4tl"
   },
   "outputs": [],
   "source": [
    "len(list(filter(lambda x:  x.detail_extracted, author_obj.publications)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LC_LbDwF_C_9",
    "outputId": "11524e82-03b8-4098-eab0-75574a99ad1b"
   },
   "outputs": [],
   "source": [
    "len(author_obj.publications)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
